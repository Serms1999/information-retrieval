{
 "cells": [
  {
   "cell_type": "code",
   "id": "957b8a8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:02.280925Z",
     "start_time": "2024-04-07T18:41:02.279500Z"
    }
   },
   "source": [
    "# jupyter nbconvert --to script assignment1Ander.ipynb\n"
   ],
   "outputs": [],
   "execution_count": 272
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:03.551928Z",
     "start_time": "2024-04-07T18:41:02.451750Z"
    }
   },
   "source": [
    "!pip install pandas nltk scikit-learn"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/serms/.config/python_envs/information-retrieval/lib/python3.12/site-packages (2.2.1)\r\n",
      "Requirement already satisfied: nltk in /Users/serms/.config/python_envs/information-retrieval/lib/python3.12/site-packages (3.8.1)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/serms/.config/python_envs/information-retrieval/lib/python3.12/site-packages (1.4.1.post1)\r\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /Users/serms/.config/python_envs/information-retrieval/lib/python3.12/site-packages (from pandas) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/serms/.config/python_envs/information-retrieval/lib/python3.12/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/serms/.config/python_envs/information-retrieval/lib/python3.12/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/serms/.config/python_envs/information-retrieval/lib/python3.12/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: click in /Users/serms/.config/python_envs/information-retrieval/lib/python3.12/site-packages (from nltk) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /Users/serms/.config/python_envs/information-retrieval/lib/python3.12/site-packages (from nltk) (1.3.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/serms/.config/python_envs/information-retrieval/lib/python3.12/site-packages (from nltk) (2023.12.25)\r\n",
      "Requirement already satisfied: tqdm in /Users/serms/.config/python_envs/information-retrieval/lib/python3.12/site-packages (from nltk) (4.66.2)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/serms/.config/python_envs/information-retrieval/lib/python3.12/site-packages (from scikit-learn) (1.12.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/serms/.config/python_envs/information-retrieval/lib/python3.12/site-packages (from scikit-learn) (3.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/serms/.config/python_envs/information-retrieval/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n"
     ]
    }
   ],
   "execution_count": 273
  },
  {
   "cell_type": "code",
   "id": "8b7d3377bdb5e1af",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:03.555278Z",
     "start_time": "2024-04-07T18:41:03.553359Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from typing import Tuple, List, Dict, Union\n",
    "import nltk"
   ],
   "outputs": [],
   "execution_count": 274
  },
  {
   "cell_type": "code",
   "id": "88d221b76ddf2d70",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:03.601043Z",
     "start_time": "2024-04-07T18:41:03.556231Z"
    }
   },
   "source": [
    "dtypes = {\n",
    "    'ArticleId': 'int32',\n",
    "    'Text': 'str',\n",
    "    'Category': 'category'\n",
    "}\n",
    "data_train = pd.read_csv('data/BBC News Train.csv', dtype=dtypes, encoding='utf-8')\n",
    "data_test = pd.read_csv('data/BBC News Test.csv', dtype={'ArticleId': 'int32', 'Text': 'str'}, encoding='utf-8')\n",
    "data_test_solution = pd.read_csv('data/BBC News Sample Solution.csv', dtype={'ArticleId': 'int32', 'Category': 'category'}, encoding='utf-8')\n",
    "data_test['Category'] = data_test_solution['Category']\n",
    "data = pd.concat([data_train, data_test])\n",
    "data.head(10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   ArticleId                                               Text       Category\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...       business\n",
       "1        154  german business confidence slides german busin...       business\n",
       "2       1101  bbc poll indicates economic gloom citizens in ...       business\n",
       "3       1976  lifestyle  governs mobile choice  faster  bett...           tech\n",
       "4        917  enron bosses in $168m payout eighteen former e...       business\n",
       "5       1582  howard  truanted to play snooker  conservative...       politics\n",
       "6        651  wales silent on grand slam talk rhys williams ...          sport\n",
       "7       1797  french honour for director parker british film...  entertainment\n",
       "8       2034  car giant hit by mercedes slump a slump in pro...       business\n",
       "9       1866  fockers fuel festive film chart comedy meet th...  entertainment"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1582</td>\n",
       "      <td>howard  truanted to play snooker  conservative...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>651</td>\n",
       "      <td>wales silent on grand slam talk rhys williams ...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1797</td>\n",
       "      <td>french honour for director parker british film...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2034</td>\n",
       "      <td>car giant hit by mercedes slump a slump in pro...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1866</td>\n",
       "      <td>fockers fuel festive film chart comedy meet th...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 275
  },
  {
   "cell_type": "code",
   "id": "96ce9018b2a8fbac",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:03.607018Z",
     "start_time": "2024-04-07T18:41:03.602700Z"
    }
   },
   "source": [
    "data.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2225 entries, 0 to 734\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   ArticleId  2225 non-null   int32   \n",
      " 1   Text       2225 non-null   object  \n",
      " 2   Category   2225 non-null   category\n",
      "dtypes: category(1), int32(1), object(1)\n",
      "memory usage: 45.8+ KB\n"
     ]
    }
   ],
   "execution_count": 276
  },
  {
   "cell_type": "code",
   "id": "2b05d327a4857f09",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:03.610547Z",
     "start_time": "2024-04-07T18:41:03.607601Z"
    }
   },
   "source": [
    "data.Category.value_counts()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "sport            493\n",
       "business         483\n",
       "politics         421\n",
       "entertainment    420\n",
       "tech             408\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 277
  },
  {
   "cell_type": "markdown",
   "id": "eb35a3128315a8a1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "id": "2c02022a24763cd0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:03.612719Z",
     "start_time": "2024-04-07T18:41:03.611195Z"
    }
   },
   "source": [
    "def lowercase_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    new_data = data.copy()\n",
    "    new_data['Text'] = new_data['Text'].str.lower()\n",
    "    return new_data"
   ],
   "outputs": [],
   "execution_count": 278
  },
  {
   "cell_type": "markdown",
   "id": "f6db4930c7a4763d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "id": "fff3a6acf4b32ed5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:03.614824Z",
     "start_time": "2024-04-07T18:41:03.613284Z"
    }
   },
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def remove_punctuation(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    tokenizer = RegexpTokenizer(r'[a-z]+')\n",
    "    new_data = data.copy()\n",
    "    new_data['Text'] = new_data['Text'].apply(tokenizer.tokenize)\n",
    "    return new_data"
   ],
   "outputs": [],
   "execution_count": 279
  },
  {
   "cell_type": "markdown",
   "id": "583e7f0fb29903",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "id": "acb1e2b503a01671",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:03.632700Z",
     "start_time": "2024-04-07T18:41:03.615444Z"
    }
   },
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_stopwords(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    new_data = data.copy()\n",
    "    new_data['Text'] = new_data['Text'].apply(lambda x: [word for word in tuple(x) if word not in stop_words and len(word) > 3])\n",
    "    return new_data"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1000)>\n"
     ]
    }
   ],
   "execution_count": 280
  },
  {
   "cell_type": "markdown",
   "id": "10682d5495dc5e81",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "id": "f241c8565dfa7777",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:03.651198Z",
     "start_time": "2024-04-07T18:41:03.633496Z"
    }
   },
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "def lemmatize_data(data: pd.DataFrame) -> Tuple[pd.DataFrame, WordNetLemmatizer]:\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    new_data = data.copy()\n",
    "    new_data['Text'] = new_data['Text'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x]))\n",
    "    return new_data, lemmatizer"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1000)>\n"
     ]
    }
   ],
   "execution_count": 281
  },
  {
   "cell_type": "markdown",
   "id": "cf095e767b5ab599",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "id": "f452ad5f0e0d5e81",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:03.667932Z",
     "start_time": "2024-04-07T18:41:03.653424Z"
    }
   },
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('punkt')\n",
    "def stem_data(data: pd.DataFrame) -> Tuple[pd.DataFrame, PorterStemmer]:\n",
    "    stemmer = PorterStemmer()\n",
    "    new_data = data.copy()\n",
    "    new_data['Text'] = new_data['Text'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x]))\n",
    "    return new_data, stemmer"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1000)>\n"
     ]
    }
   ],
   "execution_count": 282
  },
  {
   "cell_type": "markdown",
   "id": "2130cede11e039e7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Compute tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "id": "f27bae2e536b60ad",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:03.670894Z",
     "start_time": "2024-04-07T18:41:03.668619Z"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_tfidf(data: pd.DataFrame, *, min_df: float = 0.05, max_df: float = 0.1, stop_words_language: str = 'english', max_features: int = 100) -> Tuple[TfidfVectorizer, pd.DataFrame]:\n",
    "    # Drop rows with NaN values in the 'Text' column\n",
    "    data = data.dropna(subset=['Text'])\n",
    "    vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df,  stop_words=stop_words_language, max_features=max_features)\n",
    "    \n",
    "    X = vectorizer.fit_transform(data['Text'])\n",
    "    return vectorizer, X"
   ],
   "outputs": [],
   "execution_count": 283
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:03.673112Z",
     "start_time": "2024-04-07T18:41:03.671485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def data_preprocessing(data: Union[pd.DataFrame, List]) -> pd.DataFrame:\n",
    "    if isinstance(data, list):\n",
    "        data = pd.DataFrame(data, columns=['Text'])\n",
    "    data = lowercase_data(data)\n",
    "    data = remove_punctuation(data)\n",
    "    data = remove_stopwords(data)\n",
    "    return data"
   ],
   "id": "18e30d2a23a2c220",
   "outputs": [],
   "execution_count": 284
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:03.675224Z",
     "start_time": "2024-04-07T18:41:03.673622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def lemmatize_or_stem_data(data: pd.DataFrame, lemmatize: bool = True) -> Tuple[pd.DataFrame, WordNetLemmatizer]:\n",
    "    if lemmatize:\n",
    "        return lemmatize_data(data)\n",
    "    return stem_data(data)"
   ],
   "id": "a55f827ab143e99b",
   "outputs": [],
   "execution_count": 285
  },
  {
   "cell_type": "code",
   "id": "8daaf06aa595e909",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:04.678703Z",
     "start_time": "2024-04-07T18:41:03.675951Z"
    }
   },
   "source": [
    "data = data_preprocessing(data)\n",
    "data, lem_stem_vectorizer = lemmatize_or_stem_data(data, lemmatize=True)\n",
    "# data_stemmed = stem_data(data)"
   ],
   "outputs": [],
   "execution_count": 286
  },
  {
   "cell_type": "code",
   "id": "a7f487ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:04.688661Z",
     "start_time": "2024-04-07T18:41:04.686798Z"
    }
   },
   "source": [
    "#user_interests = {\n",
    "#     1: ['politics', 'soccer'],\n",
    "#     2: ['music', 'films'],\n",
    "#     3: ['cars', 'politics'],\n",
    "#     4: ['soccer']\n",
    "# }"
   ],
   "outputs": [],
   "execution_count": 287
  },
  {
   "cell_type": "code",
   "id": "1385db31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:04.694928Z",
     "start_time": "2024-04-07T18:41:04.693115Z"
    }
   },
   "source": [
    "user_interests = {\n",
    "    1: ['politics'],\n",
    "    2: ['entertainment'],\n",
    "    3: ['sport'],\n",
    "    4: ['tech'],\n",
    "    5: ['business']\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 288
  },
  {
   "cell_type": "code",
   "id": "a00ea52c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:04.883472Z",
     "start_time": "2024-04-07T18:41:04.695642Z"
    }
   },
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vectorizer, document_vectors = get_tfidf(data, min_df=0.0, max_df=0.05, stop_words_language='english', max_features=1000)"
   ],
   "outputs": [],
   "execution_count": 289
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:04.886141Z",
     "start_time": "2024-04-07T18:41:04.884137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "\n",
    "def preprocess_user_interests(user_interests: Dict[int, List[str]]) -> Dict[int, List[str]]:\n",
    "    interests_processed = {}\n",
    "    for user_id, interests in user_interests.items():\n",
    "         interests_processed[user_id] = flatten(data_preprocessing(interests)['Text'].to_list())\n",
    "    return interests_processed"
   ],
   "id": "978fc7f2037507da",
   "outputs": [],
   "execution_count": 290
  },
  {
   "cell_type": "code",
   "id": "a1a0a9e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:04.897200Z",
     "start_time": "2024-04-07T18:41:04.886762Z"
    }
   },
   "source": [
    "num_documents_to_retrieve = 10  # Number of documents to retrieve for each user\n",
    "user_relevant_documents: Dict[int, List[Tuple[int, float]]] = {}\n",
    "categories = data['Category'].unique()\n",
    "\n",
    "for user_id, interests in preprocess_user_interests(user_interests).items():\n",
    "    relevant_documents: List[Tuple[int, float]] = []\n",
    "    for interest in interests:\n",
    "        interest2 = lem_stem_vectorizer.lemmatize(interest)\n",
    "        query_vector = vectorizer.transform([interest2])\n",
    "        similarity_scores = cosine_similarity(query_vector, document_vectors)[0]\n",
    "        top_documents_indices = similarity_scores.argsort()[-num_documents_to_retrieve:][::-1]\n",
    "        top_documents: List[Tuple[int, float]] = [(data.iloc[i]['ArticleId'], similarity_scores[i]) for i in top_documents_indices]\n",
    "        relevant_documents.extend(top_documents)\n",
    "    \n",
    "    # Sort the relevant documents by their similarity scores\n",
    "    relevant_documents.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    user_relevant_documents[user_id] = relevant_documents"
   ],
   "outputs": [],
   "execution_count": 291
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:04.900423Z",
     "start_time": "2024-04-07T18:41:04.897816Z"
    }
   },
   "cell_type": "code",
   "source": "user_relevant_documents",
   "id": "78893c6d84e95c99",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [(1792, 0.7408856831837601),\n",
       "  (642, 0.5592710769276793),\n",
       "  (825, 0.4823601107731745),\n",
       "  (553, 0.45191177920047976),\n",
       "  (613, 0.3417742921961316),\n",
       "  (2211, 0.31446432399649277),\n",
       "  (14, 0.31098090160057457),\n",
       "  (86, 0.31098090160057457),\n",
       "  (882, 0.2891740022375368),\n",
       "  (1104, 0.2709810314485538)],\n",
       " 2: [(985, 0.6096620994463217),\n",
       "  (84, 0.41090477570057116),\n",
       "  (1147, 0.38513858369268944),\n",
       "  (326, 0.32485876883885145),\n",
       "  (1090, 0.3076501360110294),\n",
       "  (716, 0.29229709963955747),\n",
       "  (332, 0.23938478253891698),\n",
       "  (992, 0.23801186843872937),\n",
       "  (1841, 0.23024466644340688),\n",
       "  (1821, 0.2275906502547173)],\n",
       " 3: [(471, 0.0),\n",
       "  (1280, 0.0),\n",
       "  (1555, 0.0),\n",
       "  (1234, 0.0),\n",
       "  (1874, 0.0),\n",
       "  (231, 0.0),\n",
       "  (1995, 0.0),\n",
       "  (1994, 0.0),\n",
       "  (1860, 0.0),\n",
       "  (245, 0.0)],\n",
       " 4: [(1174, 0.4188148218582689),\n",
       "  (1805, 0.3862573014139449),\n",
       "  (2218, 0.25303704426275203),\n",
       "  (645, 0.25303704426275203),\n",
       "  (1241, 0.25035470952674327),\n",
       "  (626, 0.24638118212209764),\n",
       "  (631, 0.23318543779605272),\n",
       "  (2168, 0.20515731929925923),\n",
       "  (722, 0.20515731929925923),\n",
       "  (450, 0.2009698170798863)],\n",
       " 5: [(471, 0.0),\n",
       "  (1280, 0.0),\n",
       "  (1555, 0.0),\n",
       "  (1234, 0.0),\n",
       "  (1874, 0.0),\n",
       "  (231, 0.0),\n",
       "  (1995, 0.0),\n",
       "  (1994, 0.0),\n",
       "  (1860, 0.0),\n",
       "  (245, 0.0)]}"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 292
  },
  {
   "cell_type": "markdown",
   "id": "c8dc0aa3",
   "metadata": {},
   "source": [
    "solucionar esto, devuelve lo mismo para sport y para business"
   ]
  },
  {
   "cell_type": "code",
   "id": "410b1f45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:04.903315Z",
     "start_time": "2024-04-07T18:41:04.900998Z"
    }
   },
   "source": [
    "user_relevant_documents[5] == user_relevant_documents[3]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 293
  },
  {
   "cell_type": "code",
   "id": "aca545f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:04.906284Z",
     "start_time": "2024-04-07T18:41:04.904009Z"
    }
   },
   "source": [
    "categories"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business', 'tech', 'politics', 'sport', 'entertainment']\n",
       "Categories (5, object): ['business', 'entertainment', 'politics', 'sport', 'tech']"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 294
  },
  {
   "cell_type": "markdown",
   "id": "2462b25c",
   "metadata": {},
   "source": [
    "User 1 Interests: ['politics']\n",
    "     Document: court halt mark morrison album Similarity Score: 0.5719763\n",
    "     Document: confusion high definition crit Similarity Score: 0.55491936\n",
    "     Document: ethiopia crop production ethio Similarity Score: 0.5127802\n",
    "     Document: detention ruling urged governm Similarity Score: 0.5117885\n",
    "     Document: santy worm make unwelcome visi Similarity Score: 0.50219214\n",
    "     Document: ukip candidate suspended euros Similarity Score: 0.5007821\n",
    "     Document: bosvelt optimistic deal manche Similarity Score: 0.49390337\n",
    "     Document: adriano chelsea link rejected  Similarity Score: 0.49390337\n",
    "     Document: copy protection strengthened d Similarity Score: 0.49235088\n",
    "     Document: italy ireland moment magic bri Similarity Score: 0.481332"
   ]
  },
  {
   "cell_type": "code",
   "id": "21b6b812",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:42:06.611879Z",
     "start_time": "2024-04-07T18:42:06.609525Z"
    }
   },
   "source": [
    "# Print or use user_relevant_documents as needed\n",
    "for user_id, relevant_documents in user_relevant_documents.items():\n",
    "    print(f\"User {user_id} relevant documents:\")\n",
    "    for i, (document_id, document_text, similarity_score) in enumerate(relevant_documents, start=1):\n",
    "        print(f\"{i}. Document ID: {document_id}\\nDocument Text: {document_text}\\nSimilarity Score: {similarity_score:.4f}\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1 relevant documents:\n",
      "1. Document ID: 1792\n",
      "\n",
      "Similarity Score: 0.7409\n",
      "\n",
      "2. Document ID: 642\n",
      "\n",
      "Similarity Score: 0.5593\n",
      "\n",
      "3. Document ID: 825\n",
      "\n",
      "Similarity Score: 0.4824\n",
      "\n",
      "4. Document ID: 553\n",
      "\n",
      "Similarity Score: 0.4519\n",
      "\n",
      "5. Document ID: 613\n",
      "\n",
      "Similarity Score: 0.3418\n",
      "\n",
      "6. Document ID: 2211\n",
      "\n",
      "Similarity Score: 0.3145\n",
      "\n",
      "7. Document ID: 14\n",
      "\n",
      "Similarity Score: 0.3110\n",
      "\n",
      "8. Document ID: 86\n",
      "\n",
      "Similarity Score: 0.3110\n",
      "\n",
      "9. Document ID: 882\n",
      "\n",
      "Similarity Score: 0.2892\n",
      "\n",
      "10. Document ID: 1104\n",
      "\n",
      "Similarity Score: 0.2710\n",
      "\n",
      "User 2 relevant documents:\n",
      "1. Document ID: 985\n",
      "\n",
      "Similarity Score: 0.6097\n",
      "\n",
      "2. Document ID: 84\n",
      "\n",
      "Similarity Score: 0.4109\n",
      "\n",
      "3. Document ID: 1147\n",
      "\n",
      "Similarity Score: 0.3851\n",
      "\n",
      "4. Document ID: 326\n",
      "\n",
      "Similarity Score: 0.3249\n",
      "\n",
      "5. Document ID: 1090\n",
      "\n",
      "Similarity Score: 0.3077\n",
      "\n",
      "6. Document ID: 716\n",
      "\n",
      "Similarity Score: 0.2923\n",
      "\n",
      "7. Document ID: 332\n",
      "\n",
      "Similarity Score: 0.2394\n",
      "\n",
      "8. Document ID: 992\n",
      "\n",
      "Similarity Score: 0.2380\n",
      "\n",
      "9. Document ID: 1841\n",
      "\n",
      "Similarity Score: 0.2302\n",
      "\n",
      "10. Document ID: 1821\n",
      "\n",
      "Similarity Score: 0.2276\n",
      "\n",
      "User 3 relevant documents:\n",
      "1. Document ID: 471\n",
      "\n",
      "Similarity Score: 0.0000\n",
      "\n",
      "2. Document ID: 1280\n",
      "\n",
      "Similarity Score: 0.0000\n",
      "\n",
      "3. Document ID: 1555\n",
      "\n",
      "Similarity Score: 0.0000\n",
      "\n",
      "4. Document ID: 1234\n",
      "\n",
      "Similarity Score: 0.0000\n",
      "\n",
      "5. Document ID: 1874\n",
      "\n",
      "Similarity Score: 0.0000\n",
      "\n",
      "6. Document ID: 231\n",
      "\n",
      "Similarity Score: 0.0000\n",
      "\n",
      "7. Document ID: 1995\n",
      "\n",
      "Similarity Score: 0.0000\n",
      "\n",
      "8. Document ID: 1994\n",
      "\n",
      "Similarity Score: 0.0000\n",
      "\n",
      "9. Document ID: 1860\n",
      "\n",
      "Similarity Score: 0.0000\n",
      "\n",
      "10. Document ID: 245\n",
      "\n",
      "Similarity Score: 0.0000\n",
      "\n",
      "User 4 relevant documents:\n",
      "1. Document ID: 1174\n",
      "\n",
      "Similarity Score: 0.4188\n",
      "\n",
      "2. Document ID: 1805\n",
      "\n",
      "Similarity Score: 0.3863\n",
      "\n",
      "3. Document ID: 2218\n",
      "\n",
      "Similarity Score: 0.2530\n",
      "\n",
      "4. Document ID: 645\n",
      "\n",
      "Similarity Score: 0.2530\n",
      "\n",
      "5. Document ID: 1241\n",
      "\n",
      "Similarity Score: 0.2504\n",
      "\n",
      "6. Document ID: 626\n",
      "\n",
      "Similarity Score: 0.2464\n",
      "\n",
      "7. Document ID: 631\n",
      "\n",
      "Similarity Score: 0.2332\n",
      "\n",
      "8. Document ID: 2168\n",
      "\n",
      "Similarity Score: 0.2052\n",
      "\n",
      "9. Document ID: 722\n",
      "\n",
      "Similarity Score: 0.2052\n",
      "\n",
      "10. Document ID: 450\n",
      "\n",
      "Similarity Score: 0.2010\n",
      "\n",
      "User 5 relevant documents:\n",
      "1. Document ID: 471\n",
      "\n",
      "Similarity Score: 0.0000\n",
      "\n",
      "2. Document ID: 1280\n",
      "\n",
      "Similarity Score: 0.0000\n",
      "\n",
      "3. Document ID: 1555\n",
      "\n",
      "Similarity Score: 0.0000\n",
      "\n",
      "4. Document ID: 1234\n",
      "\n",
      "Similarity Score: 0.0000\n",
      "\n",
      "5. Document ID: 1874\n",
      "\n",
      "Similarity Score: 0.0000\n",
      "\n",
      "6. Document ID: 231\n",
      "\n",
      "Similarity Score: 0.0000\n",
      "\n",
      "7. Document ID: 1995\n",
      "\n",
      "Similarity Score: 0.0000\n",
      "\n",
      "8. Document ID: 1994\n",
      "\n",
      "Similarity Score: 0.0000\n",
      "\n",
      "9. Document ID: 1860\n",
      "\n",
      "Similarity Score: 0.0000\n",
      "\n",
      "10. Document ID: 245\n",
      "\n",
      "Similarity Score: 0.0000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 297
  },
  {
   "cell_type": "code",
   "id": "fe1617e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:04.918370Z",
     "start_time": "2024-04-07T18:41:04.918319Z"
    }
   },
   "source": [
    "# Print or use user_relevant_documents as needed\n",
    "for user_id, relevant_documents in user_relevant_documents.items():\n",
    "    print(f\"User {user_id} relevant documents:\")\n",
    "    for i, (document_id, document_text, similarity_score) in enumerate(relevant_documents, 1):\n",
    "        print(f\"{i}. Document ID: {document_id}\\nDocument Text: {document_text}\\nSimilarity Score: {similarity_score:.4f}\\n\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0eb21beb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:04.919105Z",
     "start_time": "2024-04-07T18:41:04.918882Z"
    }
   },
   "source": [
    "# from evaltools import evaluate"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fce7f083",
   "metadata": {},
   "source": [
    "evaluar cin la funcion del profesor"
   ]
  },
  {
   "cell_type": "code",
   "id": "9963448c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:41:04.920008Z",
     "start_time": "2024-04-07T18:41:04.919939Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "# from evaltools import evaluate, generate_relevance_array\n",
    "Q = []\n",
    "R = []\n",
    "def get_category(doc_id):\n",
    "    return data.loc[data['ArticleId'] == doc_id, 'Category'].values[0]\n",
    "\n",
    "for user_id, interests in user_interests.items():\n",
    "    print(user_id)\n",
    "    print(interests)\n",
    "    # Transform the user's interests into a query vector\n",
    "    article_ids = [doc_id for doc_id, _, _ in user_relevant_documents[user_id]]\n",
    "    print(article_ids)\n",
    "    Q.append(article_ids)\n",
    "    \n",
    "    # Extract the ids of the relevant documents for the user\n",
    "    R.append([1 if any(interest == get_category(doc_id) for interest in interests) else -1 for doc_id, _, _ in user_relevant_documents[user_id]])\n",
    "    # R.append([1 if interests[0] == get_category(doc_id) else -1 for doc_id, _, _ in user_relevant_documents[user_id]])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "81612a74",
   "metadata": {},
   "source": [
    "for i in range(len(Q)):\n",
    "    print(len(Q[i]), len(R[i]))\n",
    "    # IF ANY VALUE IS NAN, THE TEST WILL FAIL\n",
    "    if len(Q[i]) != len(R[i]):\n",
    "        print(f\"Mismatch in lengths at index {i}: len(Q[{i}]) = {len(Q[i])}, len(R[{i}]) = {len(R[i])}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f3f26676",
   "metadata": {},
   "source": [
    "def evaluate(ex,Q,R):\n",
    "    nq=len(Q)\n",
    "    nd=len(Q[0])\n",
    "    R_=np.array(R)\n",
    "    R_=.5*(R_+1)\n",
    "    Prec_tot=[]\n",
    "    Rec_tot=[]    \n",
    "    \n",
    "    def compute_PR(print_screen=True):\n",
    "        Prec_tot=[]\n",
    "        Rec_tot=[]        \n",
    "        if print_screen:\n",
    "            print('Precision and Recall at k for k=1,...,%d' % nd)      \n",
    "        for q in range(nq):\n",
    "            q1 = q + 1\n",
    "            r = R_[q,:]\n",
    "            if print_screen:\n",
    "                print('\\tQuery %d' % q1)\n",
    "            Prec_q=[]\n",
    "            Rec_q=[]\n",
    "            for k in range(nd):\n",
    "                k1 = k + 1\n",
    "                Prec=np.sum(r[:k1])/k1\n",
    "                Rec=np.sum(r[:k1])/np.sum(r)    \n",
    "                # if np.sum(r) == 0:\n",
    "                #     Prec = 0\n",
    "                #     Rec = 0\n",
    "                # else:\n",
    "                #     Prec = np.sum(r[:k1]) / k1\n",
    "                #     Rec = np.sum(r[:k1]) / np.sum(r)\n",
    "                if print_screen:                    \n",
    "                    print('\\t\\tP(%d)=%d/%d=%.2f,\\tR(%d)=%d/%d=%.2f' % (k1, np.sum(r[:k1]), k1, Prec, k1, np.sum(r[:k1]), np.sum(r), Rec))\n",
    "                Prec_q.append(Prec)\n",
    "                Rec_q.append(Rec)\n",
    "            Prec_tot.append(Prec_q)\n",
    "            Rec_tot.append(Rec_q)\n",
    "        Prec_tot = np.array(Prec_tot)\n",
    "        Rec_tot = np.array(Rec_tot)\n",
    "        return Prec_tot, Rec_tot\n",
    "\n",
    "    def compute_TPFP(TP_rate=None):\n",
    "        TP_tot=[]        \n",
    "        FP_tot=[]        \n",
    "        print('TP_rate and FP_rate at k for k=1,...,%d'%nd)      \n",
    "        for q in range(nq):\n",
    "            q1=q+1\n",
    "            r=R_[q,:]\n",
    "            nr=1-r\n",
    "            print('\\tQuery %d'%q1)\n",
    "            TP_q=[]\n",
    "            FP_q=[]\n",
    "            for k in range(nd):\n",
    "                k1=k+1\n",
    "                TP=np.sum(r[:k1])/np.sum(r)                \n",
    "                FP=np.sum(nr[:k1])/np.sum(nr)\n",
    "                \n",
    "                print('\\t\\tTP_rate(%d)=R(%d)=%d/%d=%.2f\\t FP_rate(%d)=%d/%d=%.2f\\t'\\\n",
    "                     %(k1, k1, np.sum(r[:k1]),np.sum(r),TP, k1,np.sum(nr[:k1]),np.sum(nr),FP))\n",
    "                TP_q.append(TP)\n",
    "                FP_q.append(FP)\n",
    "            TP_tot.append(TP_q)\n",
    "            FP_tot.append(FP_q)\n",
    "        TP_tot=np.array(TP_tot)\n",
    "        FP_tot=np.array(FP_tot)\n",
    "        return TP_tot, FP_tot        \n",
    "    if ex=='prec_rec' or ex=='all':        \n",
    "        Prec_tot, Rec_tot=compute_PR()\n",
    "        print('\\n Draw the Precision-Recall curve for each query')  \n",
    "        # print(f\"Precision: {Prec_tot}, Recall: {Rec_tot}\")\n",
    "        for q in range(nq):\n",
    "            q1=q+1\n",
    "            print('\\tQuery %d'%q1)            \n",
    "            plt.figure()\n",
    "            Rec_q=Rec_tot[q,:]\n",
    "            Prec_q=Prec_tot[q,:]\n",
    "            # print(f\"Rec_q: {Rec_q}, rec_q: {Prec_q}\")\n",
    "            plt.scatter(np.array(Rec_q), np.array(Prec_q))\n",
    "            plt.plot(np.array(Rec_q), np.array(Prec_q),label='Precision-Recall curve')            \n",
    "            plt.xlim([-0.05,1.05]); plt.ylim([-0.05,1.05])\n",
    "            plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "            R_int=np.hstack([0,Rec_q,1])\n",
    "            # print(f\"R_int: {R_int}\")\n",
    "            P_int=np.zeros(R_int.size)\n",
    "            # print(f\"P_int: {P_int}\")\n",
    "            for i_r in range(R_int.size-1):\n",
    "                r=R_int[i_r]\n",
    "                if i_r!=0 and R_int[i_r+1]==r:\n",
    "                    P_int[i_r]=np.max(Prec_q[i_r-1:])    \n",
    "                else:\n",
    "                    P_int[i_r]=np.max(Prec_q[i_r:])            \n",
    "            plt.plot(R_int,P_int,color='r',label='Interpolated PR curve')\n",
    "            plt.legend(loc='lower left')\n",
    "            plt.show()\n",
    "    if ex=='r-prec' or ex=='all':        \n",
    "        if Prec_tot.size == 0:\n",
    "            Prec_tot, Rec_tot=compute_PR()\n",
    "        print('\\n Determine R-precision for each query') \n",
    "        for q in range(nq):            \n",
    "            Rec_q=Rec_tot[q,:]\n",
    "            Prec_q=Prec_tot[q,:]\n",
    "            r=int(np.sum(R_[q]))\n",
    "            q1=q+1\n",
    "            print('\\tQuery %d'%q1)\n",
    "            print('\\t\\tNumber of relevant documents: %d --> P(%d)=%.2f'%(r,r,Prec_q[r-1]))\n",
    "    if ex=='map' or ex=='all':        \n",
    "        if Prec_tot.size == 0:\n",
    "            Prec_tot, Rec_tot=compute_PR()\n",
    "        print('\\n Calculate the Mean Average Precision')\n",
    "        APs=[]\n",
    "        for q in range(nq):            \n",
    "            Prec_q=Prec_tot[q,:]            \n",
    "            r=int(np.sum(R_[q]))\n",
    "            q1=q+1\n",
    "            print('\\tQuery %d'%q1)\n",
    "            str_formula='1/%d '%r\n",
    "            rs=np.where(R_[q]==1)[0]+1\n",
    "            str_formula+='{' + ' + '.join(['P(%d)'%rs_ for rs_ in rs]) + '}'\n",
    "            AP=np.mean(Prec_q[np.where(R_[q]==1)])            \n",
    "            print('\\t\\tAP=%s=%.2f'%(str_formula, AP))\n",
    "            APs.append(AP)\n",
    "        APstring='1/%d {'%nq\n",
    "        APstring+= ' + '.join(['AP_%d'%(q+1) for q in range(nq)]) \n",
    "        APstring+='}=1/%d {'%nq\n",
    "        APstring+= ' + '.join(['%.2f'%(AP) for AP in APs]) \n",
    "        APstring+='}'        \n",
    "        print('\\tMAP=%s=%.2f'%(APstring, np.mean(np.array(APs))))\n",
    "    if ex=='roc' or ex=='all' or ex=='auc':\n",
    "        TP_tot, FP_tot=compute_TPFP()    \n",
    "        print('\\n Draw the ROC curve for each query')  \n",
    "        for q in range(nq):\n",
    "            q1=q+1\n",
    "            print('\\tQuery %d'%q1)            \n",
    "            plt.figure()\n",
    "            TP_q=TP_tot[q,:]\n",
    "            FP_q=FP_tot[q,:]\n",
    "            plt.scatter(np.array(FP_q), np.array(TP_q))\n",
    "            TP_q_=np.hstack([0,TP_q,1])\n",
    "            FP_q_=np.hstack([0,FP_q,1])\n",
    "            plt.plot(np.array(FP_q_), np.array(TP_q_),label='ROC curve')            \n",
    "            plt.xlim([-0.05,1.05]); plt.ylim([-0.05,1.05])\n",
    "            plt.xlabel('FP rate'); plt.ylabel('TP rate')\n",
    "            plt.show()\n",
    "            if ex=='auc' or ex=='all':\n",
    "                AUC=[]\n",
    "                for i_x in range(TP_q_.size-1):\n",
    "                    delta_x=FP_q_[i_x+1]-FP_q_[i_x]\n",
    "                    base=TP_q_[i_x+1]+TP_q_[i_x]\n",
    "                    AUC.append(base*delta_x/2)\n",
    "                AUC=np.array(AUC)\n",
    "                AUC=AUC[AUC>0]\n",
    "                string_AUC=' + '.join(['%.2f'%auc for auc in AUC])\n",
    "                if string_AUC!='':\n",
    "                    string_AUC+=' = '    \n",
    "                print('\\tAUC = %s %.2f\\n\\n'%(string_AUC, np.sum(AUC)))            \n",
    "    if ex=='clear':\n",
    "        return"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9063dbb5",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "evaluate('all', Q, R)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "# Datos de ejemplo (debes reemplazarlos con tus propios datos)\n",
    "documents = data['Text']\n",
    "\n",
    "# Tokenizar los documentos y crear objetos TaggedDocument\n",
    "tagged_data = [TaggedDocument(words=doc.split(), tags=[str(i)]) for i, doc in enumerate(documents)]\n",
    "print(len(tagged_data))\n",
    "# Entrenar el modelo Doc2Vec\n",
    "\n",
    "model = Doc2Vec(window=5, min_count=1, workers=4, epochs=20)\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "document_embeddings = [model.dv[str(i)] for i in range(len(documents))]\n",
    "\n",
    "# Process user queries\n",
    "for user_id, interests in user_interests.items():\n",
    "#     interests preprocesamiento\n",
    "    # Aggregate word embeddings for the user's interests to generate the query embedding\n",
    "    interests = lem_stem_vectorizer.lemmatize(''.join(interests))\n",
    "    #     interests = stemmer.stem(''.join(interests))\n",
    "#     interests = stemmer.(interests)\n",
    "    query_embedding = model.infer_vector([interests])\n",
    "    \n",
    "    cosine_similarities = cosine_similarity([query_embedding], document_embeddings)[0]\n",
    "\n",
    "    top_k=10\n",
    "    top_documents_indices = cosine_similarities.argsort()[-top_k:][::-1]\n",
    "    top_documents = [(documents[i], cosine_similarities[i]) for i in range(len(top_documents_indices))]\n",
    "    \n",
    "    \n",
    "    # Store relevant documents for evaluation\n",
    "    user_relevant_documents[user_id] = top_documents\n",
    "    \n",
    "    # Print or process relevant documents\n",
    "    print(\"User\", user_id, \"Interests:\", interests)\n",
    "    for doc, score in top_documents:\n",
    "        print(\"Document:\", doc, \"Similarity Score:\", score)"
   ],
   "id": "4932ee2d1c251dab",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bd92dbc45892251f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Using word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "id": "8284385b",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Load pre-trained word embeddings\n",
    "word_embeddings_model = api.load(\"word2vec-google-news-300\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cd2dfde4",
   "metadata": {},
   "source": [
    "     Document: munster switched spain munster heineken quarter final biarritz april switched real sociedad paseo anoeta stadium sebastian real ground hold whereas parc sport aguilera biarritz capacity irish province given least ticket decision move difficult considered fan primary objective said biarritz chairman marcel martin hope rewarded huge crowd behaving best rugby tradition match first heineken fixture played spain expected attract biggest ever attendance rugby match country ulster last irish team play paseo anoeta stadium faced euskarians side season tour Similarity Score: 0.5979421\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "54c8e3fc",
   "metadata": {},
   "source": [
    "for user_id, interests in user_interests.items():\n",
    "    print(interests)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d2b36b50",
   "metadata": {},
   "source": [
    "VERSION NUEVA PARA PROBAR LO DE EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "id": "4cb3c079",
   "metadata": {},
   "source": [
    "# Function to generate document embeddings\n",
    "def generate_document_embeddings(documents, word_embeddings_model):\n",
    "    document_embeddings = []\n",
    "    for doc in documents:\n",
    "        # Aggregate word embeddings (e.g., by averaging)\n",
    "        words = doc.split()\n",
    "        embeddings = [word_embeddings_model[word] for word in words if word in word_embeddings_model]\n",
    "        if embeddings:\n",
    "            doc_embedding = np.mean(embeddings, axis=0)  # Average embeddings\n",
    "            document_embeddings.append(doc_embedding)\n",
    "    return np.array(document_embeddings)\n",
    "\n",
    "# Function to retrieve relevant documents for a query\n",
    "def retrieve_documents(query_embedding, document_embeddings, documents, document_ids):\n",
    "    similarity_scores = cosine_similarity(query_embedding.reshape(1, -1), document_embeddings)[0]\n",
    "    sorted_documents_indices = similarity_scores.argsort()[::-1]\n",
    "    sorted_documents = [(document_ids[i], documents[i], similarity_scores[i]) for i in sorted_documents_indices]\n",
    "    return sorted_documents"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e7f0ffa8",
   "metadata": {},
   "source": [
    "# Example documents \n",
    "documents = data['Text']\n",
    "document_ids = data['ArticleId']\n",
    "# Generate document embeddings\n",
    "document_embeddings = generate_document_embeddings(documents, word_embeddings_model)\n",
    "\n",
    "# Process user queries\n",
    "for user_id, interests in user_interests.items():\n",
    "    # Aggregate word embeddings for the user's interests to generate the query embedding\n",
    "    query_embedding = np.mean([word_embeddings_model[word] for interest in interests for word in interest.split() if word in word_embeddings_model], axis=0)\n",
    "    \n",
    "    # Retrieve relevant documents for the user's query\n",
    "    relevant_documents = retrieve_documents(query_embedding, document_embeddings, documents, document_ids)\n",
    "\n",
    "    # Store relevant documents for evaluation\n",
    "    user_relevant_documents[user_id] = relevant_documents\n",
    "    \n",
    "    # Print or process relevant documents\n",
    "    print(\"User\", user_id, \"Interests:\", interests)\n",
    "    for doc_id, doc, score in relevant_documents:\n",
    "        print(\"     Document ID:\", doc_id, \"Document:\", doc, \"Similarity Score:\", score)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "af0650d3",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "Q = []\n",
    "R = []\n",
    "def get_category(doc_id):\n",
    "    return data.loc[data['ArticleId'] == doc_id, 'Category'].values[0]\n",
    "\n",
    "for user_id, interests in user_interests.items():\n",
    "    print(user_id)\n",
    "    print(interests)\n",
    "    # Transform the user's interests into a query vector\n",
    "    article_ids = [doc_id for doc_id, _, _ in user_relevant_documents[user_id]]\n",
    "    print(article_ids)\n",
    "    Q.append(article_ids)\n",
    "    \n",
    "    # Extract the ids of the relevant documents for the user\n",
    "    R.append([1 if any(interest == get_category(doc_id) for interest in interests) else -1 for doc_id, _, _ in user_relevant_documents[user_id]])\n",
    "    # R.append([1 if interests[0] == get_category(doc_id) else -1 for doc_id, _, _ in user_relevant_documents[user_id]])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "63ae4b77",
   "metadata": {},
   "source": [
    "for i in range(len(Q)):\n",
    "    if len(Q[i]) != len(R[i]):\n",
    "        print(f\"Length mismatch at index {i}: len(Q[i]) = {len(Q[i])}, len(R[i]) = {len(R[i])}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c092d8ce",
   "metadata": {},
   "source": [
    "print(len(Q))\n",
    "print(len(R))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "284dc598",
   "metadata": {},
   "source": [
    "\n",
    "# Now you can call the evaluate function\n",
    "evaluate('all', Q, R)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0dc9af90",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

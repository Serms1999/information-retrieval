{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loinc_num                                   long_common_name  \\\n",
      "0     1988-5  C reactive protein [Mass/volume] in Serum or P...   \n",
      "43   30522-7  C reactive protein [Mass/volume] in Serum or P...   \n",
      "10    4671-4                  Protein C [Mass/volume] in Plasma   \n",
      "8     2143-6          Cortisol [Mass/volume] in Serum or Plasma   \n",
      "21    1968-7  Bilirubin.direct [Mass/volume] in Serum or Plasma   \n",
      "..       ...                                                ...   \n",
      "11   18864-9                        Ampicillin [Susceptibility]   \n",
      "24    8310-5                                   Body temperature   \n",
      "17     925-8                   Blood product disposition [Type]   \n",
      "48   18955-5                    Nitrofurantoin [Susceptibility]   \n",
      "66   23658-8                  Other Antibiotic [Susceptibility]   \n",
      "\n",
      "                                           component    system property  \\\n",
      "0                                 C reactive protein  Ser/Plas     MCnc   \n",
      "43                                C reactive protein  Ser/Plas     MCnc   \n",
      "10                                         Protein C      Plas     MCnc   \n",
      "8                                           Cortisol  Ser/Plas     MCnc   \n",
      "21  Bilirubin.glucuronidated+Bilirubin.albumin bound  Ser/Plas     MCnc   \n",
      "..                                               ...       ...      ...   \n",
      "11                                        Ampicillin   Isolate     Susc   \n",
      "24                                  Body temperature  ^Patient     Temp   \n",
      "17                         Blood product disposition      ^BPU     Type   \n",
      "48                                    Nitrofurantoin   Isolate     Susc   \n",
      "66                                    Antibiotic XXX   Isolate     Susc   \n",
      "\n",
      "    relevance score  Similarity  \n",
      "0                 3    1.000000  \n",
      "43                3    0.970143  \n",
      "10                3    0.727607  \n",
      "8                 2    0.685994  \n",
      "21                3    0.685994  \n",
      "..              ...         ...  \n",
      "11                2    0.000000  \n",
      "24                3    0.000000  \n",
      "17                2    0.000000  \n",
      "48                1    0.000000  \n",
      "66                3    0.000000  \n",
      "\n",
      "[67 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Read data from Excel file into a DataFrame, skipping the empty row and starting from the third row\n",
    "file_path = 'data/loinc_dataset-v2.xlsx'\n",
    "df = pd.read_excel(file_path, skiprows=2)\n",
    "df = df.dropna()\n",
    "\n",
    "# Extract features for the query row\n",
    "query_row = df.iloc[0]  # Assuming the first row is the query\n",
    "query_features = query_row[['loinc_num', 'long_common_name', 'component', 'system']].astype(str)\n",
    "\n",
    "\n",
    "# Combine the text columns into a single string for vectorization\n",
    "query_text = ' '.join(query_features.values)\n",
    "\n",
    "# Vectorize the text using TF-IDF for the query\n",
    "vectorizer = TfidfVectorizer()\n",
    "query_vectorized = vectorizer.fit_transform([query_text])\n",
    "\n",
    "# Initialize a list to store similarity scores\n",
    "similarity_scores = []\n",
    "\n",
    "# Iterate through each data row until the next empty row and calculate similarity\n",
    "for index, row in df.iterrows():\n",
    "    # Check for an empty row\n",
    "    if row.isnull().all():\n",
    "        break\n",
    "    \n",
    "    data_features = row[['loinc_num', 'long_common_name', 'component', 'system']].astype(str)\n",
    "    data_text = ' '.join(data_features.values)\n",
    "    \n",
    "    # Vectorize the text using TF-IDF for the data row\n",
    "    data_vectorized = vectorizer.transform([data_text])\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity_score = cosine_similarity(query_vectorized, data_vectorized)[0][0]\n",
    "    \n",
    "    # Append similarity score to the list\n",
    "    similarity_scores.append(similarity_score)\n",
    "\n",
    "# Add similarity scores to the DataFrame\n",
    "df['Similarity'] = similarity_scores\n",
    "\n",
    "# Sort DataFrame by similarity in descending order\n",
    "ranked_df = df.sort_values(by='Similarity', ascending=False)\n",
    "\n",
    "# Display the ranked DataFrame\n",
    "print(ranked_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1.000000\n",
      "1     0.342997\n",
      "2     0.242536\n",
      "3     0.000000\n",
      "4     0.685994\n",
      "        ...   \n",
      "62    0.242536\n",
      "63    0.000000\n",
      "64    0.000000\n",
      "65    0.641689\n",
      "66    0.000000\n",
      "Name: Similarity, Length: 67, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['Similarity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esto no esta bien, es aplicando lo de la regresion pero vaya qye no esta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m data_vectorized \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform([data_text])\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Use logistic regression to predict rank (binary classification)\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m logistic_score \u001b[38;5;241m=\u001b[39m logistic_model\u001b[38;5;241m.\u001b[39mfit(query_vectorized, [\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39mdata_vectorized\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mpredict_proba(data_vectorized)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Append logistic score to the list\u001b[39;00m\n\u001b[0;32m     43\u001b[0m logistic_scores\u001b[38;5;241m.\u001b[39mappend(logistic_score[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\ander\\Anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ander\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1252\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1250\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1253\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1254\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1255\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1256\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1257\u001b[0m     )\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1260\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Read data from Excel file into a DataFrame, skipping the empty row and starting from the third row\n",
    "file_path = 'loinc_dataset-v2.xlsx'\n",
    "df = pd.read_excel(file_path, skiprows=2)\n",
    "df = df.dropna()\n",
    "\n",
    "# Extract features for the query row\n",
    "query_row = df.iloc[0]  # Assuming the first row is the query\n",
    "query_features = query_row[['loinc_num', 'long_common_name', 'component', 'system']].astype(str)\n",
    "\n",
    "# Combine the text columns into a single string for vectorization\n",
    "query_text = ' '.join(query_features.values)\n",
    "\n",
    "# Vectorize the text using TF-IDF for the query\n",
    "vectorizer = TfidfVectorizer()\n",
    "query_vectorized = vectorizer.fit_transform([query_text])\n",
    "\n",
    "# Initialize a list to store logistic regression scores\n",
    "logistic_scores = []\n",
    "\n",
    "# Initialize logistic regression model\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Iterate through each data row until the next empty row and apply logistic regression\n",
    "for index, row in df.iterrows():\n",
    "    # Check for an empty row\n",
    "    if row.isnull().all():\n",
    "        break\n",
    "    \n",
    "    data_features = row[['loinc_num', 'long_common_name', 'component', 'system']].astype(str)\n",
    "    data_text = ' '.join(data_features.values)\n",
    "    \n",
    "    # Vectorize the text using TF-IDF for the data row\n",
    "    data_vectorized = vectorizer.transform([data_text])\n",
    "    \n",
    "    # Use logistic regression to predict rank (binary classification)\n",
    "    logistic_score = logistic_model.fit(query_vectorized, [1]*len(data_vectorized)).predict_proba(data_vectorized)[:, 1]\n",
    "    \n",
    "    # Append logistic score to the list\n",
    "    logistic_scores.append(logistic_score[0])\n",
    "\n",
    "# Add logistic scores to the DataFrame\n",
    "df['Logistic_Score'] = logistic_scores\n",
    "\n",
    "# Sort DataFrame by logistic score in descending order\n",
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
